{"cells":[{"cell_type":"markdown","metadata":{"id":"YbJM10vaR1Br"},"source":["## 1. Loading prereqs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zN-Ho07_oqBg"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    IN_COLAB = True\n","    print(\"Running on Google Colab. \")\n","except:\n","    IN_COLAB = False\n","    print(\"Not running on Google Colab. \")\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import os\n","    os.chdir(\"/content/drive/Shareddrives/AI4CYBSEC\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQ-NGoOGNt2I"},"outputs":[],"source":["if IN_COLAB:\n","    !pip install facenet-pytorch\n","    !pip install Pillow"]},{"cell_type":"markdown","metadata":{"id":"hSU0qGu7Z5cr"},"source":["## 2. Load Models\n","### 2.1 Load NN1"]},{"cell_type":"markdown","metadata":{"id":"f1ycl1LPTqsz"},"source":["#### Load pre-trained model\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXc7QMPuSeco"},"outputs":[],"source":["# utilizzo la libreria facenet_pytorch per caricare il modello InceptionResnetV1 preaddestrato sul dataset VGGFace2 e abilitare la classificazione.\n","from facenet_pytorch import InceptionResnetV1\n","import torch\n","\n","resnet = InceptionResnetV1(pretrained='vggface2').eval()\n","resnet.classify = True\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print('Running on device: {}'.format(device))\n","resnet = resnet.to(device)"]},{"cell_type":"markdown","metadata":{"id":"GzhAQvqdS9Ko"},"source":["#### Loading labels of model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tc_BifakDUrs"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Il modello è addestrato sulle seguenti Labels:\n","# Carico le labels del dataset VGGFACE\n","fpath = tf.keras.utils.get_file('rcmalli_vggface_labels_v2.npy',\n","                             \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy\",\n","                             cache_subdir=\"./\")\n","LABELS = np.load(fpath) # List of name\n","# Clean list of name\n","for i in range(len(LABELS)):\n","  LABELS[i] = LABELS[i].strip().replace(' ', '').replace('\"', '')"]},{"cell_type":"markdown","metadata":{"id":"YcGt1IiKoqBk"},"source":["### 2.2 Load NN2\n","\n","#### Load repository for NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgK9tBShoqBk"},"outputs":[],"source":["# se non è presente la cartella VGGFACE2_pytorch  clone il repository\n","import os\n","if not os.path.exists('VGGFace2_pytorch'):\n","    !git clone https://github.com/cydonia999/VGGFace2-pytorch.git\n","    !mv VGGFace2-pytorch VGGFace2_pytorch"]},{"cell_type":"markdown","metadata":{"id":"_W6k4RvEoqBl"},"source":["#### Import from repository and import for operation"]},{"cell_type":"code","source":["%cd /content/drive/Shareddrives/AI4CYBSEC/"],"metadata":{"id":"mRXsrjP_14Q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHYLFhCdoqBl"},"outputs":[],"source":["from VGGFace2_pytorch.models import senet as SENet\n","from VGGFace2_pytorch.models.resnet import resnet50 as ResNet\n","from VGGFace2_pytorch import utils\n","from VGGFace2_pytorch.trainer import Validator\n","from torch.utils.data import DataLoader\n","from VGGFace2_pytorch.datasets.vgg_face2 import VGG_Faces2\n","from torch.nn.modules.loss import CrossEntropyLoss"]},{"cell_type":"markdown","metadata":{"id":"XEJx1KxKoqBl"},"source":["#### Load Model from pickle file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTvftRtQoqBl"},"outputs":[],"source":["import torchsummary\n","\n","model = SENet.senet50(num_classes = 8631, include_top = True)\n","if IN_COLAB:\n","    weights_pickel = \"/content/drive/Shareddrives/AI4CYBSEC/in_progress/senet50_ft_weight.pkl\"\n","else:\n","    weights_pickel = \"./in_progress/senet50_ft_weight.pkl\"\n","\n","utils.load_state_dict(model, weights_pickel)\n","\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","torchsummary.summary(model, (3, 224, 224))"]},{"cell_type":"markdown","metadata":{"id":"Cepg-ZkuZgbH"},"source":["## 3. Load Test Set"]},{"cell_type":"markdown","metadata":{"id":"N-4qw1-MTw2m"},"source":["#### Connect to Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-P6LcqwHEkk8"},"outputs":[],"source":["if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"L-NwB2gKZDLX"},"source":["#### Load the label of Test Set (for NN1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaAhwqLCXx4Q"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# set the path for the dataset\n","if IN_COLAB:\n","  path_dataset = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset\"\n","else:\n","    path_dataset = \"./face_dataset\"\n","\n","identity_meta_NN1_name = \"meta_identity_NN1.csv\"\n","\n","path_identity_csv = os.path.join(path_dataset,identity_meta_NN1_name)\n","identity_meta_NN1 = pd.read_csv(path_identity_csv)"]},{"cell_type":"markdown","metadata":{"id":"2H276KCNaKsJ"},"source":["## 4. Mapping different label encoding"]},{"cell_type":"markdown","metadata":{"id":"y03_Y7IqoqBn"},"source":["### 4.1 Mapping label for NN1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evxVsnB6aPTG"},"outputs":[],"source":["# I want a dictonary related to the label of the Test Set that map the name of celebrities with label associated\n","name_to_id = {}\n","id_to_name = {}\n","\n","for index, row in identity_meta_NN1.iterrows():\n","    # Ora puoi accedere ai valori di ogni riga come segue:\n","    class_id = row['Class_ID']\n","    name = row['Name']\n","    name_to_id[name]=class_id\n","    id_to_name[class_id] = name"]},{"cell_type":"markdown","metadata":{"id":"kVWllj2_oqBn"},"source":["### 4.2 Mapping label for NN2\n","\n","#### Function to create image list file for NN2 evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-lLTOWhoqBn"},"outputs":[],"source":["import os\n","\n","def create_image_list_file(root_dir, output_file, ext = '.jpg'):\n","\n","    image_paths = []\n","\n","    for class_id in os.listdir(root_dir):\n","        class_dir = os.path.join(root_dir, class_id)\n","\n","        if os.path.isdir(class_dir):\n","\n","            for filename in os.listdir(class_dir):\n","\n","                if filename.endswith(ext):\n","                    image_path = f\"{os.path.basename(root_dir)}/{class_id}/{filename}\"\n","                    image_paths.append(image_path)\n","\n","    with open(output_file, 'w') as f:\n","        for image_path in image_paths:\n","            f.write(image_path + '\\n')\n","\n","    print(f\"File di output creato con successo: {output_file}\")"]},{"cell_type":"markdown","metadata":{"id":"y9aV1t_EoqBn"},"source":["#### Mapping pipline NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LivDtla-oqBn"},"outputs":[],"source":["test_set_NN2 = \"test_set_MTCNN_NN2\"\n","\n","if IN_COLAB:\n","    output_file = '/content/drive/Shareddrives/AI4CYBSEC/image_list_file_NN2.txt'\n","    meta_file = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/identity_meta.csv\"\n","else:\n","    output_file = 'image_list_file_NN2.txt'\n","    meta_file = \"./face_dataset/identity_meta.csv\"\n","\n","root_dir = os.path.join(path_dataset,test_set_NN2)\n","\n","create_image_list_file(root_dir, output_file)\n","\n","id_label_dict = utils.get_id_label_map(meta_file)"]},{"cell_type":"markdown","metadata":{"id":"o5aQtJxlwUE4"},"source":["## 5. Evaluate model\n","\n","### 5.1 Evaluate model NN1\n","\n","#### Dataset Class for NN1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCGxCH5YqSQQ"},"outputs":[],"source":["from PIL import Image\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","\n","class VGGFace2Dataset(Dataset):\n","    def __init__(self, root_dir, image_size=(160, 160), transform=None):\n","        self.root_dir = root_dir\n","        self.image_size = image_size\n","        self.transform = transform\n","\n","        # List of files in the dataset\n","        self.file_list = []\n","        for root, dirs, files in os.walk(self.root_dir):\n","            for file in files:\n","                self.file_list.append(os.path.join(root, file))\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.file_list[idx]\n","        img = Image.open(img_path).resize(self.image_size)\n","\n","        # Extract the label from the file path\n","        label = os.path.split(os.path.dirname(img_path))[-1]\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label"]},{"cell_type":"markdown","metadata":{"id":"foZQE3LkdGCj"},"source":["#### Utility Function for NN1 with mapping labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gjQcj8Ij6gr"},"outputs":[],"source":["from PIL import Image\n","from torchvision import transforms\n","import torch\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from tqdm import tqdm\n","\n","def load_image(file_path):\n","    \"\"\" carica un'immagine da un percorso e la apre come un'immagine utilizzando Image.open dal modulo Pillow.\n","    Successivamente, ridimensiona l'immagine a dimensioni 160x160 pixel e la converte in un tensore utilizzando\n","    transforms.ToTensor() dal modulo torchvision.transforms.\n","    Infine, restituisce sia il tensore dell'immagine che l'immagine aperta.\n","    \"\"\"\n","    rsz = Image.open(file_path).resize((160, 160))\n","    tns = transforms.ToTensor()(rsz)\n","    return tns, rsz\n","\n","def make_inference(model, image_tensors, name_to_id, device):\n","    \"\"\"\n","    Takes input image tensor and returns the label associated with the network's prediction.\n","\n","    \"\"\"\n","    model.to(device)\n","    model.eval()\n","    # Move image tensors to the specified device\n","    image_tensors = image_tensors.to(device)\n","\n","    probs = model(image_tensors)\n","    #print(\"probs\", probs)\n","\n","    # Get the number of elements along the first dimension\n","    num_elements = probs.size(0)\n","\n","    # Initialize two lists to store the argmax\n","    argmax_list_1 = []\n","    argmax_list_2 = []\n","\n","    # Compute argmax for each element along the first dimension\n","    for i in range(num_elements):\n","        #target_class = np.array(probs[i].detach().cpu().numpy()).argmax()  # Move to CPU for numpy operations\n","        target_class = torch.argmax(probs[i]).item()\n","        argmax_list_1.append(name_to_id[LABELS[target_class]])\n","        argmax_list_2.append(target_class)\n","\n","    return argmax_list_1, argmax_list_2\n","\n","def validate(dataset, model,  name_to_id, device):\n","    \"\"\"\n","    Validates a model on a dataset and returns the accuracy.\n","\n","    Args:\n","        dataset: Dataset to validate the model on.\n","        model: Model to validate.\n","        device: Device to perform inference on.\n","\n","    Returns:\n","        accuracy: Accuracy of the model on the dataset.\n","    \"\"\"\n","\n","    model.to(device)\n","    model.eval()\n","    correct_predictions = 0\n","    total_samples = len(dataset) * dataset.batch_size\n","\n","    for images, labels in tqdm(dataset, desc=\"Validating model\"):\n","        #images = mtcnn(images)\n","        predicted_classes, _ = make_inference(model, images, name_to_id, device)\n","        correct_predictions += sum(pred == label for pred, label in zip(predicted_classes, labels))\n","\n","    # Compute accuracy\n","    accuracy = correct_predictions / total_samples\n","    return accuracy\n","\n","def plot_image(original_image, original_label):\n","  \"\"\"\n","  prende in ingresso le PIL.Image del campione originale e del corrispondete adversarial sample e li plotta\n","  \"\"\"\n","  plt.figure()\n","  plt.matshow(original_image)\n","  plt.title(\"Model Prediction: {}\".format(original_label))\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nNL70rmjoqBo"},"source":["### 5.2 Evaluate model NN2\n","\n","#### Utility function for NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCxMOvZjoqBp"},"outputs":[],"source":["def preprocessing_on_tensor(img_tensor, mean_bgr=np.array([91.4953, 103.8827, 131.0912])):\n","    \"\"\"\n","    Perform preprocessing on the input image tensor for the model.\n","\n","    :param img_tensor: immagine with shape (C, H, W) and values in [0, 1]\n","    :return: immagine normalizzata using mean_bgr with shape (1, C, H, W)\n","\n","    \"\"\"\n","    img = img_tensor.squeeze(0)\n","    img = img.numpy()\n","    img = (img * 255).astype(np.uint8)\n","    mean_bgr = np.array([91.4953,103.8827, 131.0912])\n","    # img è C x H x W --> H x W x C\n","    img = np.transpose(img, (1, 2, 0))\n","    img = img[:, :, ::-1]  # RGB -> BGR\n","    img = img.astype(np.float32)\n","    img -= mean_bgr\n","    img = img.transpose(2, 0, 1)\n","    img_tensor = torch.from_numpy(img).unsqueeze(0)\n","    return img_tensor\n","\n","def make_inference_NN2(model, img_tensor, device, with_preprocessing=True):\n","    \"\"\"\n","    Esegue l'inferenza su un'immagine.\n","    :param model: modello\n","    :param img_tensor: immagine trasformata\n","    :param device: dispositivo\n","    :return: predizione\n","    \"\"\"\n","    if with_preprocessing:\n","        img_tensor = img_tensor.squeeze(0)\n","        img_tensor = preprocessing_on_tensor(img_tensor)\n","    model.eval()\n","    img_tensor = img_tensor.to(device)\n","\n","    with torch.no_grad():\n","        output = model(img_tensor)\n","        pred = torch.argmax(output, dim=1).item()\n","    return pred"]},{"cell_type":"markdown","metadata":{"id":"Il_HUTmLHNMY"},"source":["# 7. CW attack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_FkFzRYH8JW"},"outputs":[],"source":["if IN_COLAB:\n","  !pip install adversarial-robustness-toolbox[all]"]},{"cell_type":"markdown","metadata":{"id":"juJoahGgiSP6"},"source":["### Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpwM412MIGgO"},"outputs":[],"source":["import numpy as np\n","import csv\n","from datetime import datetime\n","import json\n","import matplotlib.pyplot as plt\n","\n","\n","def compute_perturbation(original_images, adversarial_samples):\n","    perturbations = []\n","    for original_image, adversarial_sample in zip(original_images, adversarial_samples):\n","        perturbation = np.mean(np.abs((np.array(original_image) - np.array(adversarial_sample))))\n","        perturbations.append(perturbation)\n","    return round(float(np.mean(perturbations)),3)\n","\n","\n","def sec_curve(strength_values, accuracies_values, constant_values, strength_name, target_class=None,\n","              attack=None, avg_perturbations=None, accuracy_on_target_class=None, network=\"NN1\"):\n","    fig, ax = plt.subplots()\n","\n","    len_dataset = [998]*len(accuracies_values)\n","    # Costruisci la stringa per i valori costanti\n","    constant_str = ', '.join([f'{key}: {value}' for key, value in constant_values.items()])\n","    # line = ax.plot(np.array(strength_values), np.array(accuracies_values)/np.array(len_dataset), 'b--', label=f'{network} - {constant_str}')\n","    line = ax.plot(np.array(strength_values), np.array(accuracies_values), 'b--', label=f'{network} - {constant_str}')\n","\n","    # Aggiungi i valori costanti come parte della legenda\n","    if target_class:\n","        plt.title('Security Curve for Target Class {}'.format(target_class))\n","    else:\n","        plt.title('Security Curve')\n","\n","    # Aggiungi l'attacco al titolo\n","    if attack:\n","        plt.title(f'{attack} - {plt.gca().get_title()}')\n","\n","    plt.xlabel('Attack strength ({})'.format(strength_name))\n","    plt.ylabel('Accuracy Test')\n","    plt.grid()\n","\n","    # Aggiungi il diagramma a barre di colore arancione per avg_perturbations\n","    if avg_perturbations:\n","        x = np.array(strength_values)\n","        ax2 = ax.twinx()\n","        bar = ax2.bar(x, avg_perturbations, color='orange', alpha=0.5, width=(x[0]-x[1])/5, label='Avg Perturbations')\n","        ax2.set_ylabel('Avg Perturbations')\n","\n","    if accuracy_on_target_class:\n","        # Aggiungi la curva di accuratezza per la classe target\n","        ax.plot(np.array(strength_values), np.array(accuracy_on_target_class), 'r--', label=f'{network} - mis_targ/miss')\n","\n","    # Unisci le linee e le barre in una lista per la legenda\n","    handles, labels = ax.get_legend_handles_labels()\n","    if avg_perturbations:\n","        handles2, labels2 = ax2.get_legend_handles_labels()\n","        handles += handles2\n","        labels += labels2\n","\n","    # Mostra la legenda\n","    plt.legend(handles, labels, loc='upper left', bbox_to_anchor=(1.2, 1), shadow=True, fontsize='small')\n","    plt.show()\n","\n","\n","def save_to_csv(attack_name, targeted, target_class, strength_name, strength_values, accuracy_values,\n","                constant_values, avg_perturbations, file_path, accuracy_on_target_class=None):\n","    # Intestazione del file CSV\n","    header = [\"timestamp\", \"attacco\", \"targeted\", \"target_class\", \"strength_name\", \"strength_values\", \"accuracy_values\", \"constant_values\", \"avg_perturbations\", \"accuracy_on_target_class\"]\n","\n","    # Creazione della tupla con i valori da scrivere nel CSV\n","    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    # Converti le liste di valori in stringhe JSON\n","    strength_values_json = json.dumps(strength_values)\n","    accuracy_values_json = json.dumps(accuracy_values)\n","    avg_perturbations_json = json.dumps(avg_perturbations)  # Converti avg_perturbations in una stringa JSON\n","    # Modifica: formatta strength_values come una lista di numeri invece di una stringa JSON\n","    accuracy_values_list = [float(val) for val in accuracy_values]\n","    # Modifica: converti accuracy_values in una lista di numeri\n","    row = (timestamp, attack_name, targeted, target_class, strength_name, strength_values_json, accuracy_values_list, json.dumps(constant_values), avg_perturbations_json)\n","\n","    # Se accuracy_on_target_class è fornito e non è None, includilo nella tupla\n","    if accuracy_on_target_class is not None:\n","        accuracy_on_target_class_json = json.dumps(accuracy_on_target_class)  # Converti accuracy_on_target_class in una stringa JSON\n","        row += (accuracy_on_target_class_json,)\n","    else:\n","        row += (None,)  # Aggiungi None alla tupla\n","\n","    # Scrittura nel file CSV in modalità append ('a')\n","    with open(file_path, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","        if file.tell() == 0:  # Se il file è vuoto, scrivi l'intestazione\n","            writer.writerow(header)\n","        writer.writerow(row)\n","\n","\n","def read_csv_and_plot(csv_file_path, network=\"NN1\"):\n","    with open(csv_file_path, mode='r') as file:\n","        reader = csv.DictReader(file)\n","\n","        # va ad eliminare spazi che potrebbero dare fastidio leggendo dal csv\n","        reader.fieldnames = [name.strip() for name in reader.fieldnames]\n","\n","        for row in reader:\n","            timestamp = row[\"timestamp\"]\n","            attack_name = row[\"attacco\"]\n","            targeted = row[\"targeted\"]\n","            target_class = row[\"target_class\"]\n","            strength_name = row[\"strength_name\"]\n","            strength_values = json.loads(row[\"strength_values\"])\n","            accuracy_values = json.loads(row[\"accuracy_values\"])\n","            constant_values = json.loads(row[\"constant_values\"])\n","            avg_perturbations = json.loads(row[\"avg_perturbations\"])\n","            accuracy_on_target_class = json.loads(row[\"accuracy_on_target_class\"]) if row[\"accuracy_on_target_class\"] else None\n","\n","            # Controlla se accuracy_values è una stringa JSON e la elabora correttamente\n","            if isinstance(accuracy_values, str):\n","                accuracy_values = json.loads(accuracy_values)\n","\n","            # Controlla se strength_values è una stringa JSON e la elabora correttamente\n","            if isinstance(strength_values, str):\n","                strength_values = json.loads(strength_values)\n","\n","            # Controlla se strength_values è una stringa JSON e la elabora correttamente\n","            if isinstance(avg_perturbations, str):\n","                avg_perturbations = json.loads(avg_perturbations)\n","\n","            # Chiama la funzione sec_curve per plottare la curva\n","            sec_curve(strength_values, accuracy_values, constant_values, strength_name, target_class, attack_name, avg_perturbations, accuracy_on_target_class, network)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpvZIeyVjovc"},"outputs":[],"source":["from art.attacks.evasion import CarliniL2Method\n","from art.estimators.classification import PyTorchClassifier\n","from torch import nn\n","import torch\n","\n","from torch import nn, optim\n","import torchvision.transforms as transforms\n","\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"OQHr6kOroqBq"},"source":["## Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZe7Uug2oqBq"},"outputs":[],"source":["# preparazione parametri per inizializzare il classificatore\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","input_shape = (3,160,160)\n","nb_classes = 8631\n","loss = nn.TripletMarginLoss()\n","optimizer = optim.Adam(resnet.parameters())\n","\n","# classificatore\n","classifier = PyTorchClassifier(model=resnet, loss=loss, input_shape=input_shape, nb_classes=nb_classes, optimizer=optimizer, clip_values=(0, 1))\n"]},{"cell_type":"markdown","metadata":{"id":"TPcliP6NpuId"},"source":["## NN1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ialpUdUdoqBs"},"outputs":[],"source":["PERFORM_ATTACK_NN1 = False\n","if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN1.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN1.csv\"\n","network = \"NN1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtkQcKupYB4J"},"outputs":[],"source":["attack_name = \"C&W\"\n","targeted = False\n","target_class = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEOKq9nGoqBt"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"GFKCk9nVoqBt"},"source":["### Dataset e Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTxOU6ycoqBt"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  # Create transform for image resizing and normalization\n","  data_transform = transforms.Compose([\n","      transforms.Resize((160, 160)),\n","      transforms.ToTensor()\n","  ])\n","  # test_set_path = \"./face_dataset/test_set_MTCNN\"\n","\n","  if IN_COLAB:\n","    test_set_path = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set_MTCNN\"\n","  else:\n","    test_set_path = \"./face_dataset/test_set_MTCNN\"\n","\n","  # Define dataset\n","  dataset = VGGFace2Dataset(root_dir=test_set_path, transform=data_transform)\n","\n","  # Check the length of the dataset\n","  print(\"Dataset length:\", len(dataset))\n","\n","  # Create DataLoader\n","  batch_size = 1\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"rmYR2dfzoqBu"},"source":["### Validation on clean data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRK_q1IyoqBu"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","    acc = validate(dataloader, resnet, name_to_id, device)\n","    print(\"\\n\"+str(acc))"]},{"cell_type":"markdown","metadata":{"id":"JZLS_rtHoqBu"},"source":["### Mapping immagini e label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RrdiV0zoqBv"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","    # mapping delle immagini e delle label dal dataloader a due liste\n","    images_list = []\n","    labels_list = []\n","    images_adv_list = []\n","\n","    for image, label in dataloader:\n","        image_numpy = image.numpy()\n","        images_list.append(image_numpy)\n","        labels_list.append(label)"]},{"cell_type":"markdown","metadata":{"id":"JUDNBZK3oqBv"},"source":["## Generazione attacchi untargeted CW"]},{"cell_type":"markdown","metadata":{"id":"w4VW2DNRmA4O"},"source":["### binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4d1b8wfjx9b"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","\n","    nb_correct_bss = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img) # generazione immagine adversarial\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device) # predizione su img adversarial\n","\n","        x_clean_pred, _ = make_inference(resnet,torch.tensor(img),name_to_id,device) # predizione su img clean\n","\n","        if x_clean_pred[0] == label[0]:\n","          correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_bss += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_bss/len(images_list)) # numero img adversarial correttamente classificate\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))  # calcolo e salvataggio perturbazione rispetto a img clean\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"2x_A9pO1mFXD"},"source":["### confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bq7WbRj7mFFB"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_conf = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        x_clean_pred, _ = make_inference(resnet,torch.tensor(img),name_to_id,device)\n","\n","        if x_clean_pred[0] == label[0]:\n","          correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_conf += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_conf/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"jlA2qZmwnRpr"},"source":["### learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qCP9JHzDnYbx"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_lr = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        x_clean_pred, _ = make_inference(resnet,torch.tensor(img),name_to_id,device)\n","\n","        if x_clean_pred[0] == label[0]:\n","          correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_lr += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_lr/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"iBXGr_Dqoe_u"},"source":["### initial cost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0WY14G3omOv"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_ic = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        x_clean_pred, _ = make_inference(resnet,torch.tensor(img),name_to_id,device)\n","\n","        if x_clean_pred[0] == label[0]:\n","          correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_ic += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_ic/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"00RVJQh5pFNX"},"source":["### max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EW_cXw80pLpR"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_mi = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        x_clean_pred, _ = make_inference(resnet,torch.tensor(img),name_to_id,device)\n","\n","        if x_clean_pred[0] == label[0]:\n","          correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_mi += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_mi/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(mi_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"05Ix2hM3sfvU"},"source":["## Generazione Attacchi targeted CW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9ZkllBVsfvV"},"outputs":[],"source":["attack_name = \"C&W\"\n","PERFORM_ATTACK_NN1 = False\n","if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN1.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN1.csv\"\n","network = \"NN1\"\n","targeted = True\n","target_class = 0\n","targeted_label = np.array(target_class)\n","one_hot_bob_targeted_label = np.expand_dims(tf.keras.utils.to_categorical(targeted_label, num_classes=nb_classes), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hTbHYCVvoqBy"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"flr3oNyZsfvV"},"source":["### binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KnA0xuVsfvV"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_bss = 0\n","    nb_target_bss = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_bss += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_bss += 1\n","\n","    print(\"ACC: \", nb_target_bss/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_bss/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_bss/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"sbJyfzpNsfvV"},"source":["### confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-2m0WZJsfvV"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_conf = 0\n","    nb_target_conf = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_conf += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_conf += 1\n","\n","    print(\"ACC: \", nb_target_conf/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_conf/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_conf/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"-p-EBTLUsfvV"},"source":["### learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZn7dbw5sfvW"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_lr = 0\n","    nb_target_lr = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_lr += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_lr += 1\n","\n","    print(\"ACC: \", nb_target_lr/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_lr/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_lr/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"gQ5maDLPsfvW"},"source":["### intial cost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBe769gOsfvW"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_ic = 0\n","    nb_target_ic = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_ic += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_ic += 1\n","\n","    print(\"ACC: \", nb_target_ic/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_ic/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_ic/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"WcBrCgABsfvW"},"source":["### max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZ2X72kDsfvW"},"outputs":[],"source":["if PERFORM_ATTACK_NN1:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_mi = 0\n","    nb_target_mi = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_mi += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_mi += 1\n","\n","    print(\"ACC: \", nb_target_mi/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_mi/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_mi/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","\n","  sec_curve(mi_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"LsGweaKyoqB0"},"source":["## NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWJR0fmmoqB1"},"outputs":[],"source":["PERFORM_ATTACK_NN2 = False\n","if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN2.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN2.csv\"\n","network = \"NN2\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CSquuMHoqB1"},"outputs":[],"source":["attack_name = \"C&W\"\n","targeted = False\n","target_class = None"]},{"cell_type":"markdown","metadata":{"id":"hLyCeY0yoqB1"},"source":["### Validation on clean data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kaBeV_NKoqB1"},"outputs":[],"source":["val_dataset = VGG_Faces2(\"./face_dataset\", output_file, id_label_dict, split = 'valid')\n","val_loader = DataLoader(val_dataset, batch_size = 1)\n","\n","if torch.cuda.is_available():\n","    cuda = True\n","else:\n","    cuda = False\n","\n","validator = Validator(\n","            cmd = \"test\",\n","            cuda = cuda,\n","            model = model,\n","            criterion = nn.TripletMarginLoss(),\n","            val_loader = val_loader,\n","            log_file = \"./log_file\",\n","            print_freq = 1000,\n","        )\n","\n","acc = validator.validate()"]},{"cell_type":"markdown","metadata":{"id":"9lZ3bqWOoqB1"},"source":["Il blocco seguente serve per testare che le cose caricate per NN2 sono state correttamente caricate\n","\n","- devono venire l'accuracy del blocco di prima e le due calcolate dal blocco seguente tutte uguali"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"salaXkVWoqB1"},"outputs":[],"source":["TO_TEST_VALIDATION = False\n","\n","if TO_TEST_VALIDATION:\n","  batch_size = 1\n","  data_transform = transforms.Compose([\n","      transforms.Resize(256),\n","      transforms.CenterCrop(224),\n","      transforms.ToTensor()\n","  ])\n","\n","  if IN_COLAB:\n","    test_set_path = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set_MTCNN_NN2\"\n","  else:\n","    test_set_path = \"./face_dataset/test_set_MTCNN_NN2\"\n","\n","  # Define dataset\n","  dataset = VGGFace2Dataset(root_dir=test_set_path, image_size=(224,224), transform=data_transform)\n","\n","  # Check the length of the dataset\n","  print(\"Dataset length:\", len(dataset))\n","\n","  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","  images_list = []\n","  labels_list = []\n","  images_adv_list = []\n","  for image, label in dataloader:\n","      image_numpy = image.numpy()\n","      images_list.append(image_numpy)\n","      labels_list.append(label)\n","\n","  images_list_2 = []\n","  labels_list_2 = []\n","  images_adv_list_2 = []\n","\n","  for batch_idx, (image, label, img_files, class_id) in enumerate(val_loader):\n","      # Effettua le predizioni del modello\n","      # image numpy on device\n","\n","      image_numpy = image.numpy()\n","      images_list_2.append(image_numpy)\n","      labels_list_2.append(label)\n","\n","  correct = 0\n","  for img, label in tqdm(zip(images_list_2, labels_list_2), total=len(images_list), desc=\" Validation on clean data with make_inference_NN2 SENET\"):\n","      # così è usando il val_loader si senet\n","\n","      img = torch.tensor(img)\n","      x_test_adv_pred = make_inference_NN2(model, img, device, with_preprocessing=False)\n","      if x_test_adv_pred == label:\n","        correct +=1\n","  accuracy = correct/len(images_list)\n","  print(\"Accuracy on clean data: \", accuracy)\n","  # dobbiamo fare la trasformazione che fa SENET\n","  correct = 0\n","  for  img, label in tqdm(zip(images_list, labels_list), total=len(images_list), desc=\" Validation on clean data with make_inference_NN2 RESNET LOADER\"):\n","      img = torch.tensor(img)\n","\n","      x_test_adv_pred = make_inference_NN2(model, img, device, with_preprocessing=True)\n","      if x_test_adv_pred == id_label_dict[label[0]]:\n","        correct +=1\n","  accuracy = correct/len(images_list)\n","  print(\"Accuracy on clean data: \", accuracy)"]},{"cell_type":"markdown","metadata":{"id":"TyPntZtsoqB2"},"source":["### Creazione liste"]},{"cell_type":"markdown","metadata":{"id":"OOUvkkjIoqB2"},"source":["Dataset creato con il Dataset scritto da noi + trasformazioni richieste da NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LiWFLjiroqB2"},"outputs":[],"source":["data_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor()\n","])\n","\n","if IN_COLAB:\n","  test_set_path = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set_MTCNN_NN2\"\n","else:\n","  test_set_path = \"./face_dataset/test_set_MTCNN_NN2\"\n","# Define dataset\n","dataset = VGGFace2Dataset(root_dir=test_set_path, image_size=(224,224), transform=data_transform)\n","\n","# Check the length of the dataset\n","print(\"Dataset length:\", len(dataset))\n","\n","batch_size = 1\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","images_list = []\n","labels_list = []\n","images_adv_list = []\n","for image, label in dataloader:\n","    image_numpy = image.numpy()\n","    images_list.append(image_numpy)\n","    labels_list.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZocqHNBoqB2"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"o91bkmUhoqB3"},"source":["## Generazione attacchi untargeted CW"]},{"cell_type":"markdown","metadata":{"id":"cYsLP7TioqB3"},"source":["### binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SsoLRxSaoqB3"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","  # bss_range = [i for i in range(1, 2, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","\n","    nb_correct_bss = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img) # generazione immagine adversarial\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred= make_inference_NN2(model, x_test_adv, device) # predizione su img adversarial\n","\n","        x_clean_pred = make_inference_NN2(model,torch.tensor(img),device) # predizione su img clean\n","\n","        if x_clean_pred == id_label_dict[label[0]]:\n","          correct+=1\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","            nb_correct_bss += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_bss/len(images_list)) # numero img adversarial correttamente classificate\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))  # calcolo e salvataggio perturbazione rispetto a img clean\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"4-coTaLSoqB3"},"source":["### confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLxIQ3BDoqB3"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_conf = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        x_clean_pred = make_inference_NN2(model,torch.tensor(img),device)\n","\n","        if x_clean_pred == id_label_dict[label[0]]:\n","          correct+=1\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","            nb_correct_conf += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_conf/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"Vb0hi3wroqB4"},"source":["### learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0S4w8wdUoqB4"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_lr = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        x_clean_pred = make_inference_NN2(model,torch.tensor(img),device)\n","\n","        if x_clean_pred == id_label_dict[label[0]]:\n","          correct+=1\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","            nb_correct_lr += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_lr/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"IbeFlrVYoqB4"},"source":["### initial cost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67OuS7AjoqB4"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_ic = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        x_clean_pred = make_inference_NN2(model,torch.tensor(img),device)\n","\n","        if x_clean_pred == id_label_dict[label[0]]:\n","          correct+=1\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","            nb_correct_ic += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_ic/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"puUZgfwKoqB4"},"source":["### max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_d4swQSoqB4"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_mi = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        x_clean_pred = make_inference_NN2(model,torch.tensor(img),device)\n","\n","        if x_clean_pred == id_label_dict[label[0]]:\n","          correct+=1\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","            nb_correct_mi += 1\n","\n","    print(\"ACC: \", correct/len(images_list))\n","    accuracy_values_untargeted.append(nb_correct_mi/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(mi_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"X8cMnhrroqB5"},"source":["## Generazione Attacchi targeted CW"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpRmplNHoqB5"},"outputs":[],"source":["attack_name = \"C&W\"\n","PERFORM_ATTACK_NN2 = False\n","if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN2.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN2.csv\"\n","network = \"NN2\"\n","targeted = True\n","target_class = 0\n","targeted_label = np.array(target_class)\n","one_hot_bob_targeted_label = np.expand_dims(tf.keras.utils.to_categorical(targeted_label, num_classes=nb_classes), axis=0)"]},{"cell_type":"markdown","metadata":{"id":"TSBmSSY5oqB5"},"source":["### binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAUFTTVEoqB5"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  from tqdm import tqdm\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_bss = 0\n","    nb_target_bss = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        difference = np.subtract(img, x_test_adv)\n","\n","        # Verifica se tutti i valori nella differenza sono zero\n","        if np.all(difference == 0):\n","            continue\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","          nb_correct_bss += 1\n","        else:\n","          nb_misclassifications += 1\n","          # np.where(LABELS == id_to_name[name_to_id[LABELS[0]]])[0][0]\n","          # x_test_adv_pred_model = np.where(LABELS == id_to_name[x_test_adv_pred])[0][0]\n","          # if x_test_adv_pred_model == target_class:\n","          if x_test_adv_pred == target_class:\n","            nb_target_bss += 1\n","\n","    print(\"ACC: \", nb_target_bss/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_bss/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_bss/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lgp2sbGJoqB6"},"outputs":[],"source":["nb_target_bss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9QiaocyoqB6"},"outputs":[],"source":["nb_misclassifications"]},{"cell_type":"markdown","metadata":{"id":"1QsMf2HAoqB7"},"source":["### confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzV9mcoeoqB7"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_conf = 0\n","    nb_target_conf = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        difference = np.subtract(img, x_test_adv)\n","\n","        # Verifica se tutti i valori nella differenza sono zero\n","        if np.all(difference == 0):\n","            continue\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","          nb_correct_conf += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred == target_class:\n","            nb_target_conf += 1\n","\n","    print(\"ACC: \", nb_target_conf/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_conf/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_conf/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"cJ3ToQzKoqB7"},"source":["### learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l66B4J-IoqB8"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_lr = 0\n","    nb_target_lr = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        difference = np.subtract(img, x_test_adv)\n","\n","        # Verifica se tutti i valori nella differenza sono zero\n","        if np.all(difference == 0):\n","            continue\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","          nb_correct_lr += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred == target_class:\n","            nb_target_lr += 1\n","\n","    print(\"ACC: \", nb_target_lr/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_lr/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_lr/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"ds_lkjHvoqB8"},"source":["### intial cost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Lke-XeroqB8"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_ic = 0\n","    nb_target_ic = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        difference = np.subtract(img, x_test_adv)\n","\n","        # Verifica se tutti i valori nella differenza sono zero\n","        if np.all(difference == 0):\n","            continue\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","          nb_correct_ic += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred == target_class:\n","            nb_target_ic += 1\n","\n","    print(\"ACC: \", nb_target_ic/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_ic/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_ic/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"jd0v9SOfoqB8"},"source":["### max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nRAfO5yLoqB9"},"outputs":[],"source":["if PERFORM_ATTACK_NN2:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_mi = 0\n","    nb_target_mi = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        difference = np.subtract(img, x_test_adv)\n","\n","        # Verifica se tutti i valori nella differenza sono zero\n","        if np.all(difference == 0):\n","            continue\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred = make_inference_NN2(model, x_test_adv, device)\n","\n","        if x_test_adv_pred == id_label_dict[label[0]]:\n","          nb_correct_mi += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred == target_class:\n","            nb_target_mi += 1\n","\n","    print(\"ACC: \", nb_target_mi/len(images_list))\n","    accuracy_values_targeted.append(nb_correct_mi/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_mi/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","\n","  sec_curve(mi_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"bKUK5UPWoqB9"},"source":["## NN1 with Defense"]},{"cell_type":"markdown","metadata":{"id":"KiDNMCypoqB9"},"source":["### Load Robust Detector for pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aygj0ppQoqB9"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","if IN_COLAB:\n","    directory = \"/content/drive/Shareddrives/AI4CYBSEC/models\"\n","else:\n","    directory = \"./models\"\n","\n","def load_model(model, model_path):\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","    return model\n","\n","# Definisci il modello mobilenet_v2\n","model = models.mobilenet_v2(pretrained=True)\n","\n","# Sostituisci il classificatore dell'ultimo layer con un nuovo classificatore\n","model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n","\n","model = model.to(device)\n","\n","\n","# carica i pesi del modello addestrato\n","defence = load_model(model, os.path.join(directory,'mobilenetv2_best_binary_classifier.pth'))\n","\n","import torchsummary\n","\n","# Stampa un riassunto del modello\n","torchsummary.summary(defence, (3, 160, 160))"]},{"cell_type":"markdown","metadata":{"id":"9QgE28NioqB-"},"source":["### Utility for inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTEfvqy_oqB-"},"outputs":[],"source":["def make_inference_defence(model, img_tensor, device):\n","    #img must be a tensor with shape (N, C, H, W)\n","    model.eval()\n","    img_tensor = img_tensor.to(device)\n","    with torch.no_grad():\n","        outputs = model(img_tensor)\n","        _, predicted = torch.max(outputs, 1)\n","\n","    return predicted.item()\n","\n","def make_inference_NN1_with_defense(model,img_tensor, name_to_id, defense_model, device, isClean ):\n","    model.to(device)\n","    defense_model.to(device)\n","    prediction_defense = make_inference_defence(defense_model, img_tensor, device)\n","    if prediction_defense == 1:\n","        if not isClean:\n","            return 1, None\n","        return 0 ,None\n","\n","    return make_inference(model, img_tensor, name_to_id, device)\n","\n","def validate_with_defence(dataloader, model, name_to_id, device, defence_model, clean_data = True):\n","    \"\"\"\n","    Validates a model on a dataset and returns the accuracy.\n","\n","    Args:\n","        dataset: Dataloader to validate the model on.\n","        model: Model to validate.\n","        device: Device to perform inference on.\n","\n","    Returns:\n","        accuracy: Accuracy of the model on the dataset.\n","    \"\"\"\n","    model.to(device)\n","    model.eval()\n","    correct_predictions = 0\n","    total_samples = len(dataloader) * dataloader.batch_size\n","    num_skipped_samples = 0\n","    with torch.no_grad():  # Disable gradient calculation\n","        for images, labels in tqdm(dataloader, desc=\"Validating model\"):\n","            predicted_classes, _= make_inference_NN1_with_defense(model, images, name_to_id, defence_model, device, clean_data)\n","            if predicted_classes == 1:# significa che ho predetto come adv un campione  adv\n","                num_skipped_samples += 1\n","                correct_predictions += 1\n","                continue\n","            elif predicted_classes == 0:# significa che ho predetto come adv un campione  clean\n","                num_skipped_samples += 1\n","                continue\n","            # DATO CHE C'è il continue è come se avessi un else:\n","            correct_predictions += sum(pred == label for pred, label in zip(predicted_classes, labels))\n","\n","\n","    # Compute accuracy\n","    accuracy = correct_predictions / total_samples\n","    return accuracy, num_skipped_samples"]},{"cell_type":"markdown","metadata":{"id":"Z_WgRYBkoqB-"},"source":["### Validation on clean data with defense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aNB97o-oqB-"},"outputs":[],"source":["# Create transform for image resizing and normalization\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize((160, 160)),\n","    transforms.ToTensor()\n","])\n","\n","if IN_COLAB:\n","  test_set_path = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set_MTCNN\"\n","else:\n","  test_set_path = \"./face_dataset/test_set_MTCNN\"\n","# Define dataset\n","dataset = VGGFace2Dataset(root_dir=test_set_path, transform=data_transform)\n","\n","# Check the length of the dataset\n","print(\"Dataset length:\", len(dataset))\n","\n","# Create DataLoader\n","batch_size = 1\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","acc = validate(dataloader, resnet, name_to_id, device)\n","print(\"\\n Accuracy without defense \"+str(acc))\n","\n","acc_with_defence, num_skipped_samples = validate_with_defence(dataloader, resnet, name_to_id, device, defence, clean_data = True)\n","print(\"\\n Accuracy with defense \"+str(acc_with_defence))\n"]},{"cell_type":"markdown","metadata":{"id":"_AjdbVEPoqB_"},"source":["### Perform attacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vt2AePdroqB_"},"outputs":[],"source":["PERFORM_ATTACK_NN1_with_defense = False\n","if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN1_with_defense.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN1_with_defense.csv\"\n","network = \"NN1_with_defense\"\n","attack_name = \"C&W\""]},{"cell_type":"markdown","metadata":{"id":"ZjKvRaZdoqB_"},"source":["### Load list of images and labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNewu1UWoqB_"},"outputs":[],"source":["images_list = []\n","labels_list = []\n","images_adv_list = []\n","for image, label in dataloader:\n","    # Effettua le predizioni del modello\n","    # image numpy on device\n","    image_numpy = image.numpy()\n","    images_list.append(image_numpy)\n","    labels_list.append(label)"]},{"cell_type":"markdown","metadata":{"id":"vQeTqSL9oqB_"},"source":["## Perform Untargeted Attack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQGViwe3oqCA"},"outputs":[],"source":["targeted = False\n","target_class = None"]},{"cell_type":"markdown","metadata":{"id":"54gL1t9BoqCA"},"source":["### binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMsCUx-4oqCA"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc_with_defence]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","  # bss_range = [i for i in range(1, 2, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_bss = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img) # generazione immagine adversarial\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","\n","        x_test_adv_pred, _ = make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_correct_bss += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","\n","        # if x_clean_pred == id_label_dict[label[0]]:\n","        #   correct+=1\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_bss += 1\n","\n","    print(\"accuracy: \", correct/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_untargeted.append(nb_correct_bss/len(images_list)) # numero img adversarial correttamente classificate\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))  # calcolo e salvataggio perturbazione rispetto a img clean\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"No4B-h4SoqCB"},"source":["### confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_tUfJo-oqCB"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc_with_defence]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_conf = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_correct_conf += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_conf += 1\n","\n","    print(\"accuracy: \", correct/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_untargeted.append(nb_correct_conf/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"WImKXlD0oqCB"},"source":["### learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kd-PyC-coqCB"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc_with_defence]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_lr = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_correct_lr += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_lr += 1\n","\n","    print(\"accuracy: \", correct/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_untargeted.append(nb_correct_lr/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"c8CSdUUtoqCB"},"source":["### initial cost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lLRskQu1oqCC"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc_with_defence]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_ic = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_correct_ic += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_ic += 1\n","\n","    print(\"accuracy: \", correct/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_untargeted.append(nb_correct_ic/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"lpal-RbjoqCC"},"source":["### max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ywf_cUL4oqCC"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_untargeted = [acc_with_defence]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_mi = 0\n","    correct = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, _= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_correct_mi += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","            nb_correct_mi += 1\n","\n","    print(\"accuracy: \", correct/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_untargeted.append(nb_correct_mi/len(images_list))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(mi_range, accuracy_values_untargeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_untargeted, constant_values, avg_perturbations, results_csv)"]},{"cell_type":"markdown","metadata":{"id":"avogU-3LoqCC"},"source":["## Perform targeted attack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRAg9g56oqCC"},"outputs":[],"source":["targeted = True\n","target_class = 0\n","targeted_label = np.array(target_class)\n","one_hot_bob_targeted_label = np.expand_dims(tf.keras.utils.to_categorical(targeted_label, num_classes=nb_classes), axis=0)"]},{"cell_type":"markdown","metadata":{"id":"feRSpP_soqCC"},"source":["### Binary search step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYEHKF74oqCD"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc_with_defence]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  bss_range = [i for i in range(1, 9, 1)]\n","\n","  for binary_search_steps in tqdm(bss_range, desc='generating attacks'):\n","\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    num_skipped_samples = 0\n","    nb_correct_bss = 0\n","    nb_target_bss = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model = make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_target_bss += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_bss += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_bss += 1\n","\n","    print(\"ACC: \", nb_target_bss/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_targeted.append(nb_correct_bss/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_bss/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  bss_range = [0] + bss_range\n","\n","  strength_name='binary_search_steps'\n","  constant_values = {\"confidence\":confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","  sec_curve(bss_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, bss_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"15JweAktoqCD"},"source":["### Confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsTxuvxEoqCD"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc_with_defence]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  conf_range = [float(i) / 10 for i in range(1, 11)]\n","\n","  for confidence in tqdm(conf_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                            confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                            initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_conf = 0\n","    nb_target_conf = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","    num_skipped_samples = 0\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_target_conf += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_conf += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_conf += 1\n","\n","    print(\"ACC: \", nb_target_conf/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_targeted.append(nb_correct_conf/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_conf/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","  conf_range = [0.0] + conf_range\n","\n","  strength_name='confidence'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"max_iter\":max_iter, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","  sec_curve(conf_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, conf_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"11LWzkTMoqCD"},"source":["### Learning rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zN29PcEzoqCD"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc_with_defence]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  lr_range = [float(i)/100 for i in range(1, 11)]\n","\n","  for learning_rate in tqdm(lr_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_lr = 0\n","    nb_target_lr = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","    num_skipped_samples = 0\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_target_lr += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_lr += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_lr += 1\n","\n","    print(\"ACC: \", nb_target_lr/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_targeted.append(nb_correct_lr/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_lr/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  lr_range = [0.0] + lr_range\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"initial_const\":initial_const}\n","  strength_name='lr'\n","\n","  sec_curve(lr_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, lr_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"f1SOOxuwoqCE"},"source":["### Initial const"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrgVAIB2oqCE"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc_with_defence]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  ic_range = [i for i in range(100, 1100, 100)]\n","\n","  for initial_const in tqdm(ic_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_ic = 0\n","    nb_target_ic = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","    num_skipped_samples = 0\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_target_ic += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_ic += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_ic += 1\n","\n","    print(\"ACC: \", nb_target_ic/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_targeted.append(nb_correct_ic/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_ic/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  ic_range = [0.0] + ic_range\n","  strength_name='ic'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"max_iter\":max_iter, \"learning_rate\":learning_rate}\n","\n","\n","  sec_curve(ic_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, ic_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"BnkQ3kjgoqCE"},"source":["### Max iter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1X_c7VCMoqCF"},"outputs":[],"source":["if PERFORM_ATTACK_NN1_with_defense:\n","  binary_search_steps = 1\n","  confidence = 0.5\n","  max_iter = 5\n","  learning_rate = 0.01\n","  initial_const = 1000\n","\n","  accuracy_values_targeted = [acc_with_defence]\n","  accuracy_on_target_class = [0]\n","  avg_perturbations = [0]\n","\n","  mi_range = [i for i in range(5, 10, 1)]\n","\n","  for max_iter in tqdm(mi_range):\n","    attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                          confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                          initial_const=initial_const, targeted=targeted, verbose=False)\n","    nb_correct_mi = 0\n","    nb_target_mi = 0\n","    nb_misclassifications = 0\n","    images_adv_list = []\n","    num_skipped_samples = 0\n","\n","    for img, label in zip(images_list, labels_list):\n","        x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","\n","        images_adv_list.append(x_test_adv)\n","\n","        x_test_adv = torch.tensor(x_test_adv)\n","        x_test_adv_pred, x_test_adv_pred_model= make_inference_NN1_with_defense(resnet, x_test_adv, name_to_id, defence, device, isClean=False)\n","        if x_test_adv_pred == 1:# significa che ho predetto come adv un campione  adv\n","            num_skipped_samples += 1\n","            nb_target_mi += 1\n","            continue\n","        elif x_test_adv_pred == 0:# significa che ho predetto come adv un campione  clean\n","            num_skipped_samples += 1\n","            continue\n","        if x_test_adv_pred[0] == label[0]:\n","          nb_correct_mi += 1\n","        else:\n","          nb_misclassifications += 1\n","          if x_test_adv_pred_model[0] == target_class:\n","            nb_target_mi += 1\n","\n","    print(\"ACC: \", nb_target_mi/len(images_list))\n","    print(\"Number of skipped samples: \", num_skipped_samples)\n","    accuracy_values_targeted.append(nb_correct_mi/len(images_list))\n","    accuracy_on_target_class.append(round(nb_target_mi/nb_misclassifications, 3))\n","    avg_perturbations.append(compute_perturbation(images_list, images_adv_list))\n","\n","\n","  mi_range = [0.0] + mi_range\n","  strength_name='mi'\n","  constant_values = {\"binary_search_steps\":binary_search_steps, \"confidence\": confidence, \"learning_rate\":learning_rate, \"initial_const\":initial_const}\n","\n","\n","\n","  sec_curve(mi_range, accuracy_values_targeted, constant_values, strength_name, target_class, attack_name, avg_perturbations)\n","\n","  save_to_csv(attack_name, targeted, target_class, strength_name, mi_range, accuracy_values_targeted, constant_values, avg_perturbations, results_csv, accuracy_on_target_class)"]},{"cell_type":"markdown","metadata":{"id":"KbQM8AtYTCcK"},"source":["# Stampa SEC"]},{"cell_type":"markdown","metadata":{"id":"pNwJFbgQoqCF"},"source":["Risultati per NN1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJUhtdV2TBLe"},"outputs":[],"source":["if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN1.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN1.csv\"\n","read_csv_and_plot(results_csv)"]},{"cell_type":"markdown","metadata":{"id":"fCkAaEDHoqCF"},"source":["Risultati per NN2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thsSPNbGoqCF"},"outputs":[],"source":["if IN_COLAB:\n","    results_csv = \"/content/drive/Shareddrives/AI4CYBSEC/results/CW/attack_results_NN2.csv\"\n","else:\n","    results_csv = \"./results/CW/attack_results_NN2.csv\"\n","read_csv_and_plot(results_csv)"]},{"cell_type":"markdown","metadata":{"id":"-8Wk5Lsny57S"},"source":["# Scelta parametri ottimali untargeted e targeted"]},{"cell_type":"markdown","metadata":{"id":"PGisjeg7oqCG"},"source":["## NN1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_hUTPpToqCG"},"outputs":[],"source":["import time"]},{"cell_type":"markdown","metadata":{"id":"u0m7WsVLoqCG"},"source":["### Untargeted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNXoElCOy57S"},"outputs":[],"source":["binary_search_steps = 1\n","confidence = 0.5\n","max_iter = 5\n","learning_rate = 0.01\n","initial_const = 400\n","\n","targeted = False\n","\n","img, label = images_list[0], labels_list[0]\n","\n","attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                        confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                        initial_const=initial_const, targeted=targeted)\n","start_time = time.time()\n","x_test_adv = attack.generate(img)\n","end_time = time.time()\n","\n","x_test_adv = torch.tensor(x_test_adv)\n","\n","x_test_adv_pred, _ = make_inference(resnet, x_test_adv, name_to_id, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tv5oLbGSoqCG"},"outputs":[],"source":["print('Original Label: '+id_to_name[label[0]])\n","\n","plt.figure()\n","plt.matshow(np.transpose(x_test_adv.squeeze(0), (1,2,0)))\n","plt.title(\"Model Prediction: {}\".format(id_to_name[x_test_adv_pred[0]]))\n","plt.show()\n","\n","perturbation = compute_perturbation(img, x_test_adv)\n","print('Perturbation: ', perturbation*100,'%')\n","\n","elapsed_time = end_time - start_time\n","print('Elapsed time:', elapsed_time)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpG9AQ-IoqCG"},"outputs":[],"source":["plt.figure()\n","plt.matshow(np.transpose(img.squeeze(0), (1,2,0)))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UtP69mL4oqCH"},"source":["### Targeted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rd0hZqRgoqCH"},"outputs":[],"source":["targeted = True\n","target_class = 0\n","targeted_label = np.array(target_class)\n","one_hot_bob_targeted_label = np.expand_dims(tf.keras.utils.to_categorical(targeted_label, num_classes=nb_classes), axis=0)\n","\n","binary_search_steps = 2\n","confidence = 0.5\n","max_iter = 5\n","learning_rate = 0.01\n","initial_const = 1000\n","\n","img, label = images_list[0], labels_list[0]\n","\n","attack = CarliniL2Method(classifier=classifier, binary_search_steps=binary_search_steps,\n","                        confidence=confidence, max_iter=max_iter, learning_rate=learning_rate,\n","                        initial_const=initial_const, targeted=targeted)\n","\n","start_time = time.time()\n","x_test_adv = attack.generate(img, one_hot_bob_targeted_label)\n","end_time = time.time()\n","\n","x_test_adv = torch.tensor(x_test_adv)\n","x_test_adv_pred, x_test_adv_pred_model = make_inference(resnet, x_test_adv, name_to_id, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xh1VDij_oqCH"},"outputs":[],"source":["print('Original Label: '+id_to_name[label[0]])\n","\n","plt.figure()\n","plt.matshow(np.transpose(x_test_adv.squeeze(0), (1,2,0)))\n","plt.title(\"Model Prediction: {}\".format(id_to_name[x_test_adv_pred[0]]))\n","plt.show()\n","\n","perturbation = compute_perturbation(img, x_test_adv)\n","print('Perturbation: ', perturbation*100,'%')\n","\n","elapsed_time = end_time - start_time\n","print('Elapsed time:', elapsed_time)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}