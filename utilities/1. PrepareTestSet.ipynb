{"cells":[{"cell_type":"markdown","metadata":{"id":"5PCzCCjlV1E_"},"source":["\n","\n","\n","\n","\n","<a id=\"prereqs\"></a>\n","# 1. Loading prereqs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25997,"status":"ok","timestamp":1719072889995,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"1M0rbkn-V1FA","outputId":"e6d9dd70-2c74-44fc-d560-469ff4a1affe"},"outputs":[],"source":["!pip install facenet-pytorch  # fornisce modelli pre-addestrati PyTorch per compiti di riconoscimento facciale\n","!pip install Pillow # aggiunge il supporto per l'apertura, la manipolazione e il salvataggio di molti diversi formati di file immagine."]},{"cell_type":"markdown","metadata":{"id":"9st1sYJtSYBA"},"source":["\n","\n","\n","<a id=\"load_model\"></a>\n","# 2. Evaluating the classifier"]},{"cell_type":"markdown","metadata":{"id":"f1ycl1LPTqsz"},"source":["## Load pre-trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["dbda6621232d435aa6208ef923dc017d","b8fda7e9eb4840328e41ddfe08913636","96f4c1166ee843078bdf3f4237300ac4","eabd88f764b3467b872511021ef94339","8dc76768ff804eb59f503963f7e191e9","368cb6d8de6843088c46f04c540a21f6","7680f09343224fbe9aab673dbafaaff2","e5376fee69ca435d921e7d9be1e302ff","f6f3e8b547dd43caa1f0ed70c994390b","6a96fd98866f45b68fd50a94a1b4e498","873a840907b04d0186ca87c517bbbf06"]},"executionInfo":{"elapsed":9748,"status":"ok","timestamp":1719072924583,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"rhN4qfR2SA0X","outputId":"09851f51-1fc5-42fc-f7ce-245b75edd3d5"},"outputs":[],"source":["# utilizzo la libreria facenet_pytorch per caricare il modello InceptionResnetV1 preaddestrato sul dataset VGGFace2 e abilitare la classificazione.\n","from facenet_pytorch import InceptionResnetV1\n","\n","resnet = InceptionResnetV1(pretrained='vggface2').eval()\n","resnet.classify = True  # classify indica se il modello deve emettere le probabilità di classificazione o feature embeddings. Questo perché tipicamente le reti di face recognition vengono utilizzate avvalendosi\n","                        # degli embeddings per poter ricreare un proprio sistema di face recognition (gallery personale)"]},{"cell_type":"markdown","metadata":{"id":"Op67M-tNT3ZA"},"source":["## Define Utility Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11321,"status":"ok","timestamp":1719072938560,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"iTyREo_TTpOT"},"outputs":[],"source":["from io import BytesIO\n","from PIL import Image\n","import requests\n","from torchvision import transforms\n","import numpy as np\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","\n","def load_image(filename):\n","    \"\"\" carica un'immagine da un URL utilizzando la libreria requests,\n","    quindi la converte in un oggetto BytesIO e la apre come un'immagine utilizzando Image.open dal modulo Pillow.\n","    Successivamente, ridimensiona l'immagine a dimensioni 160x160 pixel e la converte in un tensore utilizzando\n","    transforms.ToTensor() dal modulo torchvision.transforms.\n","    Infine, restituisce sia il tensore dell'immagine che l'immagine aperta.\n","    \"\"\"\n","    response = requests.get(filename)\n","    img_bytes = BytesIO(response.content)\n","    rsz = Image.open(img_bytes).resize((160, 160))\n","    tns = transforms.ToTensor()(rsz)\n","    return tns, rsz"]},{"cell_type":"markdown","metadata":{"id":"5Esi3gzULoCA"},"source":["## Load the labels the model was trained on"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1719072942828,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"Tc_BifakDUrs","outputId":"8c7c5f3b-76fc-4c0d-b0e6-6ab7c5bfbb87"},"outputs":[],"source":["# Il modello è addestrato sulle seguenti Labels:\n","# Carico le labels del dataset VGGFACE\n","fpath = tf.keras.utils.get_file('rcmalli_vggface_labels_v2.npy',\n","                             \"https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v2.npy\",\n","                             cache_subdir=\"./\")\n","LABELS = np.load(fpath) # List of name\n","for i in range(len(LABELS)):\n","  LABELS[i] = LABELS[i].strip().replace(' ', '').replace('\"', '')\n","\n","labels = {}\n","for i in range(len(LABELS)):\n","  labels[LABELS[i]] = i"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1719072977439,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"ME6Zok8qu3z-","outputId":"39940b63-eab2-4202-bb44-15395dc1e0c8"},"outputs":[],"source":["print(LABELS)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":762,"status":"ok","timestamp":1719073084087,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"25QWrcPXvVq8","outputId":"c60b79b9-dec6-4de5-b52c-a5c813cc1073"},"outputs":[],"source":["print(labels)"]},{"cell_type":"markdown","metadata":{"id":"kTCT6TOnLs0-"},"source":["## Load VGGFace2 Dataset (fornito da Greco come tar.gz)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504611,"status":"ok","timestamp":1719073655369,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"WLkIsJ8-WVfi","outputId":"cb19216e-0d77-42bf-b578-2014299c61ff"},"outputs":[],"source":["import os\n","import random\n","import tarfile\n","import pandas as pd\n","import gdown\n","\n","# URL del file vggface2_train.tar.gz\n","url = \"https://drive.google.com/uc?export=download&id=1K56kVYHHDfLA2Anm7ga0tQolMwIPk6R8\"\n","file_name = \"vggface2_train.tar.gz\"\n","\n","# Cartella di destinazione per il download\n","download_folder = \"./downloads\"\n","\n","# Se la cartella di download non esiste, creala\n","if not os.path.exists(download_folder):\n","    os.makedirs(download_folder)\n","\n","# Percorso completo del file scaricato\n","file_path = os.path.join(download_folder, file_name)\n","\n","# Scarica il file se non è già presente nella cartella di download\n","if not os.path.exists(file_path):\n","    print(f\"Avvio del download di {file_name}\")\n","    gdown.download(url, file_path, quiet=False)\n","    print(\"Download completato.\")\n","else:\n","    print(f\"Il file {file_name} è già presente.\")"]},{"cell_type":"markdown","metadata":{"id":"yKniNgfWL1aN"},"source":["\n","## Dataset Cleaning\n","\n","A partire dal file identity_meta.csv si noti come questo risulti essere formattato in modo inappropriato: l'attributo \"name\" contiene alcuni valori con la virgola (,) rompendo pertanto la struttura del file csv. <br> Individuata la criticità, la si risolve. <br> Inoltre, si noti come il numero di label su cui è addestrato il modello è diverso dal numero di label in meta_identity.csv. Si rimuovono quindi le labels su cui il modello non è addestrato. (Filter by name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2723,"status":"ok","timestamp":1719073855388,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"0rvyMsDRWn_p","outputId":"95cea213-4acf-44f0-e66c-1b7fbd507ed4"},"outputs":[],"source":["import gdown\n","import pandas as pd\n","\n","# URL del file identity_meta.csv\n","url = \"https://drive.google.com/uc?export=download&id=1SXhc8m5PHxyM4lEWVEccSufIa8OiOjGW\"\n","\n","# Percorso di destinazione per il download del file\n","download_folder = \"./downloads\"\n","\n","# Se la cartella di download non esiste, creala\n","if not os.path.exists(download_folder):\n","    os.makedirs(download_folder)\n","\n","# Percorso completo del file scaricato\n","file_path = os.path.join(download_folder, \"identity_meta.csv\")\n","\n","# Scarica il file se non è già presente nella cartella di download\n","if not os.path.exists(file_path):\n","    print(\"Avvio del download di identity_meta.csv\")\n","    gdown.download(url, file_path, quiet=False)\n","    print(\"Download completato.\\n\")\n","else:\n","    print(\"Il file identity_meta.csv è già presente.\")\n","\n","print(\"File path: \", file_path)\n","\n","import csv\n","import csv\n","import pandas as pd\n","\n","# Lista per memorizzare le righe con numero errato di colonne\n","invalid_rows = []\n","\n","# Lista per memorizzare le righe corrette\n","valid_rows = []\n","\n","print('\\n\\nCleaning rows')\n","# Apri il file CSV e leggi le righe ignorando quelle con un numero errato di colonne\n","with open(file_path, 'r', newline='', encoding='utf-8') as file:\n","    csv_reader = csv.reader(file)\n","    for row in csv_reader:\n","        # Verifica se il numero di colonne è corretto\n","        if len(row) == 5:\n","            row[1] = row[1].strip().replace(' ', '').replace('\"', '')\n","            valid_rows.append(row)\n","        else:\n","            invalid_rows.append(row)\n","            print(f\"Riga {csv_reader.line_num} -> {row}\")\n","            name = row[1].strip('\"').strip().replace(',', '') + \" \" + row[2].strip('\"').strip()\n","            row[1] = name.strip().replace(' ', '').replace('\"', '')\n","            del row[2]\n","            print(f\"Riga aggiustata: {row}\")\n","            valid_rows.append(row)\n","\n","identity_meta_clean = pd.DataFrame(valid_rows[1:], columns=valid_rows[0])\n","\n","identity_meta_clean.to_csv(\"meta_identity_clean.csv\", index=False)\n","\n","# filtro sulle label su cui ha appreso il modello\n","for row in valid_rows[1:]:\n","  if row[1] in labels:\n","    pass\n","  else:\n","     valid_rows.remove(row)\n","\n","# Costruisci un DataFrame da data\n","identity_meta = pd.DataFrame(valid_rows[1:], columns=valid_rows[0])\n","\n","print(\"\\n\\nidentity meta data frame:\\n\", identity_meta)\n","identity_meta.to_csv(\"meta_identity_NN1.csv\", index=False)\n","# create a mapping from name and id --> il modello dà un id che è associato ad un name che nel\n","# nostro dataset risponde ad un id diverso... quindi ci serve il mapping tra name and actual id\n","name_to_id = {}\n","for index, row in identity_meta.iterrows():\n","    # Ora puoi accedere ai valori di ogni riga come segue:\n","    class_id = row['Class_ID']\n","    name = row['Name']\n","    name_to_id[name]=class_id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1719073874755,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"JxSwXgCpyXuV","outputId":"4d5402a1-2213-4ff2-bb60-311617d187ac"},"outputs":[],"source":["print(name_to_id)"]},{"cell_type":"markdown","metadata":{"id":"tn49YWRAMjd1"},"source":["## Preparing test set\n","Seleziona 100 identità a caso come da richiesta, inizializzando un seed per la riproducibilità dell'esperimento"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":653,"status":"ok","timestamp":1719074105055,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"kFOKvhwcdi70","outputId":"f1479f21-547f-4fc0-b800-5e40b4360581"},"outputs":[],"source":["import pandas as pd\n","import random\n","seed = 42\n","\n","# Estrai 100 righe casuali dal DataFrame\n","selected_df = identity_meta.sample(n=100, random_state=seed)\n","\n","# Salva le righe selezionate in un nuovo file CSV\n","selected_csv = \"selected_data.csv\"\n","selected_df.to_csv(selected_csv, index=False)\n","\n","print(\"100 righe casuali sono state estratte e salvate in:\", selected_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1719074107428,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"vFzFQ1aKfdyu","outputId":"31150119-91a3-4d9a-8a33-6f50ef05350a"},"outputs":[],"source":["df = pd.read_csv(selected_csv)\n","print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":692681,"status":"ok","timestamp":1719074855653,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"u7x6eYLNeLXu","outputId":"6eb27d1a-b752-4871-8ba2-66306bfbd69a"},"outputs":[{"name":"stderr","output_type":"stream","text":["train/n001356/0162_01.jpg: Can't create '\\\\?\\g:\\Drive condivisi\\AI4CYBSEC\\train\\n001356\\0162_01.jpg': File exists\n","train/n002014/0093_01.jpg: Can't create '\\\\?\\g:\\Drive condivisi\\AI4CYBSEC\\train\\n002014\\0093_01.jpg': No such file or directory\n","train/n002014/0771_01.jpg: Can't create '\\\\?\\g:\\Drive condivisi\\AI4CYBSEC\\train\\n002014\\0771_01.jpg': No such file or directory\n","train/n002014/0045_06.jpg: Can't create '\\\\?\\g:\\Drive condivisi\\AI4CYBSEC\\train\\n002014\\0045_06.jpg': No such file or directory\n","train/n002014/0044_01.jpg: Can't create '\\\\?\\g:\\Drive condivisi\\AI4CYBSEC\\train\\n002014\\0044_01.jpg': No such file or directory\n","tar: Truncated input file (needed 50688 bytes, only 0 available)\n","tar: Error exit delayed from previous errors.\n"]}],"source":["# esegui questo se vuoi lavorare con il dataset estratto\n","!tar -xzf \"./downloads/vggface2_train.tar.gz\""]},{"cell_type":"markdown","metadata":{"id":"m7qiFfc770Nk"},"source":["Aternativa alla cella precedente"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":804,"status":"error","timestamp":1719074151420,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"TdMs6WRM7zaH","outputId":"e13522d8-8a0b-445f-8a20-c20797b61d97"},"outputs":[],"source":["import os\n","import shutil\n","import random\n","from tqdm import tqdm\n","\n","seed = 42\n","\n","def extract_images(root, classID, num_imgs, input_folder, output_folder, seed):\n","    random.seed(seed)\n","    # Percorso della cartella contenente le immagini estratte\n","    input_class_folder = os.path.join(input_folder, str(classID))\n","    # Percorso della cartella di output per questa classe\n","    output_class_folder = os.path.join(output_folder, str(classID))\n","\n","    # Crea la cartella di output per questa classe se non esiste già\n","    os.makedirs(output_class_folder, exist_ok=True)\n","\n","    # Elenco dei file immagine nella cartella della classe\n","    image_files = [f for f in os.listdir(input_class_folder) if os.path.isfile(os.path.join(input_class_folder, f))]\n","\n","    # Seleziona un massimo di num_imgs immagini in modo casuale (se ce ne sono meno, seleziona tutte)\n","    selected_images = random.sample(image_files, min(num_imgs, len(image_files)))\n","    \n","    \n","\n","\n","\n","    # Copia e salva le immagini selezionate\n","    for image_name in selected_images:\n","        input_image_path = os.path.join(input_class_folder, image_name)\n","        output_image_path = os.path.join(output_class_folder, image_name)\n","        shutil.copyfile(input_image_path, output_image_path)\n","\n","root = \"train\"\n","num_imgs = 10\n","input_folder = \"./train\"\n","output_folder = \"./face_dataset/test_set\"\n","\n","for classID in tqdm(df[\"Class_ID\"], desc='Processing classes', unit='class'):\n","    extract_images(root, classID, num_imgs, input_folder, output_folder, seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22645,"status":"ok","timestamp":1715070981736,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"-P6LcqwHEkk8","outputId":"b3b047ad-e74b-4805-a651-9ba4bb265d4b"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKDFs10QPAxz"},"outputs":[],"source":["!mkdir /content/drive/Shareddrives/AI4CYBSEC/face_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5KMdQglMe5L"},"outputs":[],"source":["!cp -r ./test_set /content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxy74QcxOjAc"},"outputs":[],"source":["!cp -r ./selected_data.csv /content/drive/Shareddrives/AI4CYBSEC/face_dataset/selected_data.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8z4lmzaQY53"},"outputs":[],"source":["!cp -r ./meta_identity_NN1.csv /content/drive/Shareddrives/AI4CYBSEC/face_dataset/meta_identity_NN1.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YxDix4YtRX6e"},"outputs":[],"source":["!cp -r ./meta_identity_clean.csv /content/drive/Shareddrives/AI4CYBSEC/face_dataset/meta_identity_clean.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUQlMOtZPL6E"},"outputs":[],"source":["!cp -r ./downloads/identity_meta.csv /content/drive/Shareddrives/AI4CYBSEC/face_dataset/identity_meta.csv"]},{"cell_type":"markdown","metadata":{"id":"97p3HlxvZB-f"},"source":["### Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vf-DlwrPS7s7"},"outputs":[],"source":["def load_image(file_path):\n","    \"\"\" carica un'immagine da un percorso e la apre come un'immagine utilizzando Image.open dal modulo Pillow.\n","    Successivamente, ridimensiona l'immagine a dimensioni 160x160 pixel e la converte in un tensore utilizzando\n","    transforms.ToTensor() dal modulo torchvision.transforms.\n","    Infine, restituisce sia il tensore dell'immagine che l'immagine aperta.\n","    \"\"\"\n","    rsz = Image.open(file_path).resize((160, 160))\n","    tns = transforms.ToTensor()(rsz)\n","    return tns, rsz\n","\n","def make_inference(tensor_image, name_to_id):\n","  \"\"\"\n","  prende in ingresso il tensore dell'immagine e ritorna la label associata alla predizione della rete\n","  \"\"\"\n","  if len(tensor_image.shape) == 3:\n","      tensor_image = tensor_image.unsqueeze(0)\n","  probs = resnet(tensor_image)\n","  target_class = np.array(probs[0].detach().numpy()).argmax()\n","  return name_to_id[LABELS[target_class]], target_class\n","\n","def plot_image(original_image, original_label):\n","  \"\"\"\n","  prende in ingresso le PIL.Image del campione originale e del corrispondete adversarial sample e li plotta\n","  \"\"\"\n","  plt.figure()\n","  plt.matshow(original_image)\n","  plt.title(\"Model Prediction: {}\".format(original_label))\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"oK-q2EOpZEqL"},"source":["### Test model in inference on a random identity of test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":10781,"status":"ok","timestamp":1715075537340,"user":{"displayName":"PRISCO TROTTA","userId":"07883661950882496888"},"user_tz":-120},"id":"lceFbwuER3LT","outputId":"a96d6811-3aa9-4e65-8885-4a33fe362bb1"},"outputs":[],"source":["import os\n","import random\n","\n","# Percorso della directory ./test_set\n","test_set_path = \"/content/drive/Shareddrives/AI4CYBSEC/face_dataset/test_set\"\n","\n","# Ottieni un elenco di tutte le cartelle in ./test_set\n","subdirectories = [f for f in os.listdir(test_set_path) if os.path.isdir(os.path.join(test_set_path, f))]\n","\n","# Seleziona casualmente una cartella\n","random_folder = random.choice(subdirectories)\n","\n","# Percorso della cartella selezionata casualmente\n","random_folder_path = os.path.join(test_set_path, random_folder)\n","\n","# Itera su tutti i file nella cartella selezionata casualmente\n","for file_name in os.listdir(random_folder_path):\n","    file_path = os.path.join(random_folder_path, file_name)\n","    if os.path.isfile(file_path):\n","        tns, rsz = load_image(file_path)\n","        pred, target_class = make_inference(tns, name_to_id)\n","        plot_image(rsz, pred)\n","\n","        name = LABELS[target_class]\n","\n","        # double check con il file identity_meta.csv\n","        for idx,row in identity_meta.iterrows():\n","          if row['Class_ID'] == pred and row[\"Name\"] == name:\n","            print('Double check passed')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"368cb6d8de6843088c46f04c540a21f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a96fd98866f45b68fd50a94a1b4e498":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7680f09343224fbe9aab673dbafaaff2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"873a840907b04d0186ca87c517bbbf06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dc76768ff804eb59f503963f7e191e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f4c1166ee843078bdf3f4237300ac4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5376fee69ca435d921e7d9be1e302ff","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f3e8b547dd43caa1f0ed70c994390b","value":111898327}},"b8fda7e9eb4840328e41ddfe08913636":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_368cb6d8de6843088c46f04c540a21f6","placeholder":"​","style":"IPY_MODEL_7680f09343224fbe9aab673dbafaaff2","value":"100%"}},"dbda6621232d435aa6208ef923dc017d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8fda7e9eb4840328e41ddfe08913636","IPY_MODEL_96f4c1166ee843078bdf3f4237300ac4","IPY_MODEL_eabd88f764b3467b872511021ef94339"],"layout":"IPY_MODEL_8dc76768ff804eb59f503963f7e191e9"}},"e5376fee69ca435d921e7d9be1e302ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabd88f764b3467b872511021ef94339":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a96fd98866f45b68fd50a94a1b4e498","placeholder":"​","style":"IPY_MODEL_873a840907b04d0186ca87c517bbbf06","value":" 107M/107M [00:02&lt;00:00, 50.4MB/s]"}},"f6f3e8b547dd43caa1f0ed70c994390b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
