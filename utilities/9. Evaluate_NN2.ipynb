{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cydonia999/VGGFace2-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab. \")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create image list file for NN2 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_image_list_file(root_dir, output_file, ext = '.jpg'):\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    for class_id in os.listdir(root_dir):\n",
    "        class_dir = os.path.join(root_dir, class_id)\n",
    "        \n",
    "        if os.path.isdir(class_dir):\n",
    "\n",
    "            for filename in os.listdir(class_dir):\n",
    "                \n",
    "                if filename.endswith(ext):  \n",
    "                    image_path = f\"{os.path.basename(root_dir)}/{class_id}/{filename}\"  \n",
    "                    image_paths.append(image_path)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        for image_path in image_paths:\n",
    "            f.write(image_path + '\\n')\n",
    "\n",
    "    print(f\"File di output creato con successo: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of NN2 as defined in the repository of the net (black-box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from VGGFace2_pytorch.models import senet as SENet\n",
    "from VGGFace2_pytorch.models.resnet import resnet50 as ResNet\n",
    "from VGGFace2_pytorch import utils\n",
    "from VGGFace2_pytorch.trainer import Validator\n",
    "from torch.utils.data import DataLoader\n",
    "from VGGFace2_pytorch.datasets.vgg_face2 import VGG_Faces2\n",
    "\n",
    "import os\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "root_dir = \"face_dataset/test_set_MTCNN_NN2\" \n",
    "output_file = 'image_list_file_NN2.txt'\n",
    "create_image_list_file(root_dir, output_file)\n",
    "meta_file = \".\\\\face_dataset\\identity_meta.csv\"\n",
    "id_label_dict = utils.get_id_label_map(meta_file)\n",
    "model = SENet.senet50(num_classes = 8631, include_top = True)\n",
    "utils.load_state_dict(model, \".\\in_progress\\senet50_ft_weight.pkl\")\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(\"device: \", device)\n",
    "#import torchsummary\n",
    "#torchsummary.summary(model, (3, 224, 224))\n",
    "\n",
    "\n",
    "val_dataset = VGG_Faces2(\".//face_dataset\", output_file, id_label_dict, split = 'valid')\n",
    "val_loader = DataLoader(val_dataset, batch_size = 1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for batch_idx, (imgs, target, img_files, class_ids) in enumerate(val_loader):\n",
    "    imgs = imgs.to(device)\n",
    "    target = target.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(imgs)\n",
    "        print(\"Target: \", target)\n",
    "        print(\"Class ids: \", class_ids)\n",
    "        pred = torch.argmax(output, dim = 1)\n",
    "        print(\"Predictions: \", pred)\n",
    "        break\n",
    "\"\"\"\n",
    "\n",
    "validator = Validator(\n",
    "            cmd = \"test\",\n",
    "            cuda = True,\n",
    "            model = model,\n",
    "            criterion = CrossEntropyLoss(),\n",
    "            val_loader = val_loader,\n",
    "            log_file = \"./log_file\",\n",
    "            print_freq = 1000,\n",
    "        )\n",
    "\n",
    "accuracy = validator.validate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms \n",
    "def make_inference_NN2(model, img_path,  id_label_dict, device, temp_file = 'temp.txt'):\n",
    "\n",
    "    # create file temp per l'immagine .txt\n",
    "    with open(temp_file, 'w') as f:\n",
    "        f.write(img_path)\n",
    "    output_file = temp_file\n",
    "    val_dataset = VGG_Faces2(\".//face_dataset\", output_file, id_label_dict, split = 'valid')\n",
    "    val_loader = DataLoader(val_dataset, batch_size = 1)\n",
    "    validator = Validator(\n",
    "            cmd = \"test\",\n",
    "            cuda = True if \"cuda\" in device else False,\n",
    "            model = model,\n",
    "            criterion = CrossEntropyLoss(),\n",
    "            val_loader = val_loader,\n",
    "            log_file = \"./log_file\",\n",
    "            print_freq = 1000,\n",
    "        )\n",
    "    os.remove(temp_file)\n",
    "    return validator.validate(make_inference = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference\n",
    "if IN_COLAB:\n",
    "    img_path = \"/content/drive/Shareddrives/AI4CYBSEC/test_set_MTCNN_NN2/n000017/0082_01.jpg\"\n",
    "else:\n",
    "    img_path = \"test_set_MTCNN_NN2/n000017/0082_01.jpg\"\n",
    "attack = \"PGD\"\n",
    "network = \"NN2\"\n",
    "temp_file = \"temp_\"+attack+\"_\"+network+\".txt\"\n",
    "\n",
    "# come vedere se una stringa contiene un'altra stringa\n",
    "\n",
    "pred = make_inference_NN2(model, img_path, id_label_dict, device, temp_file=temp_file)\n",
    "print(\"Prediction: \", pred)\n",
    "print(\"True class: \", id_label_dict[os.path.basename(os.path.dirname(img_path))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4CyberSec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
